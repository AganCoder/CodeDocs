# 数据结构与算法（1）-- 时间复杂度与空间复杂度

标签（空格分隔）： 数据结构

---

> 本文是基于极客学院-王争《数据结构与算法之美》学习笔记与心得


![](https://static001.geekbang.org/resource/image/91/a7/913e0ababe43a2d57267df5c5f0832a7.jpg)

## 一、什么是数据结构，什么是算法

想要入职大公司，数据结构与算法是必须要迈过去的一道坎。数据结构与算法也最能体验一个人基础知识是否牢固，也大厂最喜欢考察的部分。学习数据结构与算法，能极大的提高自己的能力技术能力以及思维方式，对于以后职业发展都会有不少的好处。

那什么是数据结构呢？ 简单一句话就是“**数据的存储结构**”， 而算法就是"**操作数据的方法**"，**每一种算法要作用在特定的数据结构之上**。

算法有很多种，但是最常用的也不多:

**数据结构:** **数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树**

**算法:** **递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法**

同一组数据可以由不同的算法来进行操作。如何来评估各种算法的优劣，这就引入了复杂度的概念了。

## 二、复杂度

比较一种算法优劣，我们一般使用的是**事后统计法**，就是把算法跑一次，然后根据结果来进行判断优劣，但这种有两个弊端:

+ 测试结果非常的依赖于测试环境，这种就造成了在不同环境下，可能跑出的结果不一样。
+ 测试结果依赖于数据的规模，不同规模的数据结果可能不一样。

因此需要一种评估方式，不依赖于环境也不依赖于数据量，就能粗略的估计执行效率的方法。这就引入和**时间复杂度**和**空间复杂度**概念。

### 2.1 时间复杂度

时间复杂度，顾名思义，就是来**粗略**衡量时间的。指的就是在不运行代码的情况下，估计代码的执行时间。

个人觉得王争对于 O 的复杂度表示法的引入非常的简单易懂，那就直接引入吧

> #### 大 O 复杂度表示法
> 算法的执行效率，粗略地讲，就是算法代码执行的时间。但是，如何在不运行代码的情况下，用“肉眼”得到一段代码的执行时间呢？
>
>这里有段非常简单的代码，求 1,2,3…n 的累加和。现在，我就带你一块来估算一下这段代码的执行时间。

> ```c
int cal(int n) {
    int sum = 0; 
    int i = 1; 
    for (; i <= n; ++i) {
        sum = sum + i;
    } 
    return sum; 
}
> ``` 
>  从 CPU 的角度来看，这段代码的每一行都执行着类似的操作：读数据-运算-写数据。尽管每行代码对应的 CPU 执行的个数、执行的时间都不一样，但是，我们这里只是粗略估计，所以可以假设每行代码执行的时间都一样，为 unit_time。在这个假设的基础之上，这段代码的总执行时间是多少呢？
> 
> 第 2、3 行代码分别需要 1 个 unit_time 的执行时间，第 4、5 行都运行了 n 遍，所以需要 2n*unit_time 的执行时间，所以这段代码总的执行时间就是 (2n+2)*unit_time。可以看出来，**所有代码的执行时间 T(n) 与每行代码的执行次数成正比。**
>
> 按照这个分析思路，我们再来看这段代码。
> ```c
int cal(int n) {
    int sum = 0; 
    int i = 1; 
    int j = 1; 
    for (; i <= n; ++i) { 
        j = 1; 
        for (; j <= n; ++j) { 
            sum = sum + i * j;
        } 
    } 
}
> ```
> 我们依旧假设每个语句的执行时间是 unit_time。那这段代码的总执行时间 T(n) 是多少呢？
>
> 第 2、3、4 行代码，每行都需要 1 个 unit_time 的执行时间，第 5、6 行代码循环执行了 n 遍，需要 2n * unit_time 的执行时间，第 7、8 行代码循环执行了 n<sup>2</sup>遍，所以需要 2n<sup>2</sup> * unit_time 的执行时间。所以，整段代码总的执行时间 T(n) = (2n<sup>2</sup>+2n+3)*unit_time。
>
> 尽管我们不知道 unit_time 的具体值，但是通过这两段代码执行时间的推导过程，我们可以得到一个非常重要的规律，那就是，**所有代码的执行时间 T(n) 与每行代码的执行次数 n 成正比**。
> 
> 我们可以把这个规律总结成一个公式。注意，大 O 就要登场了！
> ![](https://static001.geekbang.org/resource/image/22/ef/22900968aa2b190072c985a08b0e92ef.png)
> 我来具体解释一下这个公式。其中，T(n) 我们已经讲过了，它表示代码执行的时间；n 表示数据规模的大小；f(n) 表示每行代码执行的次数总和。因为这是一个公式，所以用 f(n) 来表示。公式中的 O，表示代码的执行时间 T(n) 与 f(n) 表达式成正比。
> 
> 所以，第一个例子中的 T(n) = O(2n+2)，第二个例子中的 T(n) = O(2n<sup>2</sup>+2n+3)。这就是**大 O 时间复杂度表示法**。大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示**代码执行时间随数据规模增长的变化趋势**，所以，也叫作**渐进时间复杂度**（asymptotic time complexity），简称**时间复杂度**。
>
> 当 n 很大时，你可以把它想象成 10000、100000。而公式中的低阶、常量、系数三部分并不左右增长趋势，所以都可以忽略。我们只需要记录一个最大量级就可以了，如果用大 O 表示法表示刚讲的那两段代码的时间复杂度，就可以记为：T(n) = O(n)； T(n) = O(n<sup>2</sup>)。

上面很清楚的解释了大 O 时间复杂度的由来和表示方法，针对各种各样的情况，有如下三条建议

+ 只要关注循环执行次数最多的一段代码，因为复杂度表示法代表的是一种变化趋势，常量、低阶、系数等都可以忽略
 
+ 加法法则：总复杂度等于量级最大的那段代码的复杂度

+ 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积，这种就是类似于嵌套的情况









